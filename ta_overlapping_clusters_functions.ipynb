{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5452ea9-3788-4363-932b-c122962c55c8",
   "metadata": {},
   "source": [
    "# Creating Overlapping Clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95556158-6099-4a2c-831d-12d7be21621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint \n",
    "\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, GroupShuffleSplit, cross_val_score,KFold, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error, mean_squared_error, silhouette_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8e4b8-b2ae-4602-96e4-40a85c05f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "ta_ed = pd.read_csv(\"~/hollings/data/ta_orderconv.csv\")\n",
    "tst1 = pd.read_csv(\"~/hollings/data/8clovlap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0773c31-cb71-4cb4-8477-e06eb48eed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIMAL CLUSTER ALG: 8 CLUSTERS,NO LON, DEPTH as an additional predictor\n",
    "gmm_feat = [\"Latitude\", \"SST\", \"SSS\", \"Bottom Depth\"]\n",
    "gmm = GaussianMixture(n_components = 8, covariance_type = \"full\", random_state = 42)\n",
    "gmm.fit(ta_ed[gmm_feat])\n",
    "\n",
    "components = gmm.predict(ta_ed[gmm_feat])\n",
    "prob = gmm.predict_proba(ta_ed[gmm_feat])\n",
    "\n",
    "clust1 = ta_ed.loc[ta_ed[\"Cluster\"] ==0]\n",
    "clust2 = ta_ed.loc[ta_ed[\"Cluster\"] ==1]\n",
    "clust3 = ta_ed.loc[ta_ed[\"Cluster\"] ==2]\n",
    "clust4 = ta_ed.loc[ta_ed[\"Cluster\"] ==3]\n",
    "clust5 = ta_ed.loc[ta_ed[\"Cluster\"] ==4]\n",
    "clust6 = ta_ed.loc[ta_ed[\"Cluster\"] ==5]\n",
    "clust7 = ta_ed.loc[ta_ed[\"Cluster\"] ==6]\n",
    "clust8 = ta_ed.loc[ta_ed[\"Cluster\"] ==7]\n",
    "\n",
    "cluster_lst = [clust1, clust2, clust3, clust4, clust5, clust6, clust7, clust8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf8391-e3c8-454b-b1d9-b08d875453a5",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb995b8-ace2-460c-8945-84a0d8d005ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "def make_features(c_lst):\n",
    "    ft_dict = {}\n",
    "    for idx, cluster in enumerate(c_lst):\n",
    "        X1 = cluster[\"S\"] #0\n",
    "        X2 = cluster[\"PT\"] #1\n",
    "        X3 = cluster[\"Nitrate\"] #2\n",
    "        X4 = cluster[\"AOU\"] #3\n",
    "        X5 = cluster[\"Silicate\"] #4\n",
    "        #lat = cluster[\"Latitude\"] #5\n",
    "        lon20= np.cos(np.deg2rad(cluster[\"Longitude\"] - 20))#6\n",
    "        lon110= np.cos(np.deg2rad(cluster[\"Longitude\"] - 110)) #7\n",
    "        depth = cluster[\"Depth\"] #8\n",
    "        order = cluster[\"order\"] #9\n",
    "        y = cluster[\"TA\"] #10\n",
    "        cruise = cluster[\"Cruise\"] #11\n",
    "        ft_dict[idx]=[X1, X2, X3, X4, X5, lon20, lon110, depth, order, y, cruise]\n",
    "    return ft_dict\n",
    "\n",
    "#TRAIN-TEST SPLIT: split the data for each cluster\n",
    "def split_data(ft_dict):\n",
    "    split_dict = {}\n",
    "    for idx in ft_dict.keys(): #this is going thru each cluster\n",
    "        features = ft_dict[idx]\n",
    "        X, y, cruise = features[0], features[8], features[9]\n",
    "        clustersp = GroupShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 40) #this is fine\n",
    "        ind = list(clustersp.split(X, y, cruise))\n",
    "        train_ind, test_ind = ind[0][0], ind[0][1]\n",
    "        split_dict[idx] = [train_ind, test_ind]\n",
    "    return split_dict\n",
    "\n",
    "#drop y and cruise col here (need y not to be shaped this way and dont need cruise col anymore)\n",
    "def rearrange(splitted_data, ft_dict):\n",
    "    reshaped_data = {}\n",
    "    for idx in splitted_data.keys(): #going into each of the keys \n",
    "        train_index, test_index = splitted_data[idx]\n",
    "        feat_values = []\n",
    "        for i in range(len(ft_dict[idx])-3): ##added a \"-3\" to get rid of last three elements \n",
    "            re_values = []\n",
    "            train = np.array(ft_dict[idx][i])[train_index]\n",
    "            train.reshape(-1,1)\n",
    "            test = np.array(ft_dict[idx][i])[test_index]\n",
    "            test.reshape(-1,1)\n",
    "            re_values.append(train)\n",
    "            re_values.append(test)\n",
    "            feat_values.append(re_values)\n",
    "        reshaped_data[idx] = feat_values\n",
    "    return reshaped_data\n",
    "\n",
    "def y_capture(splitted_data, ft_dict):\n",
    "    y_dict = {}\n",
    "    for idx in splitted_data.keys(): #going into each of the keys \n",
    "        train_index, test_index = splitted_data[idx]\n",
    "        y_train = ft_dict[idx][9].iloc[train_index]\n",
    "        y_test = ft_dict[idx][9].iloc[test_index]\n",
    "        y_dict[idx] = (y_train, y_test)\n",
    "    return y_dict\n",
    "\n",
    "def order_capture(splitted_data, ft_dict):\n",
    "    order_dict = {}\n",
    "    for idx in splitted_data.keys(): #going into each of the keys \n",
    "        train_index, test_index = splitted_data[idx]\n",
    "        order_train = ft_dict[idx][8].iloc[train_index]\n",
    "        order_test = ft_dict[idx][8].iloc[test_index]\n",
    "        order_dict[idx] = (order_train, order_test)\n",
    "    return order_dict\n",
    "    \n",
    "def make_clust_eq(reshaped_dict):\n",
    "    tpose_dt = {}\n",
    "    for idx in reshaped_dict.keys(): #going into each cluster\n",
    "        final_set = []\n",
    "        train_eq_clust = []\n",
    "        test_eq_clust = []\n",
    "        for k in range(len(reshaped_dict[idx])):\n",
    "            train_eq_clust.append(reshaped_dict[idx][k][0]) \n",
    "            train_clust_trans = np.transpose(train_eq_clust)\n",
    "            test_eq_clust.append(reshaped_dict[idx][k][1]) \n",
    "            test_clust_trans = np.transpose(test_eq_clust)\n",
    "        final_set.append(train_clust_trans)\n",
    "        final_set.append(test_clust_trans)\n",
    "        tpose_dt[idx] = final_set\n",
    "    return tpose_dt\n",
    "\n",
    "def rfr_testset(tpose_dt, y_dict):\n",
    "    rmse_lst = []\n",
    "    for idx in tpose_dt.keys():\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(tpose_dt[idx][0], y_dict[idx][0])\n",
    "        y_pred = rf.predict(tpose_dt[idx][0])\n",
    "        rmse = root_mean_squared_error(y_dict[idx][1], y_pred)\n",
    "        rmse_lst.append(rmse)\n",
    "    return rmse_lst\n",
    "\n",
    "def rfr_rflst(tpose_dt, y_dict):\n",
    "    rmse_lst = []\n",
    "    rf_lst = []\n",
    "    norm_preds = {}\n",
    "    for idx in tpose_dt.keys():\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(tpose_dt[idx][0], y_dict[idx][0])\n",
    "        rf_lst.append(rf)\n",
    "        y_pred = rf.predict(tpose_dt[idx][0])\n",
    "        rmse = root_mean_squared_error(y_dict[idx][1], y_pred)\n",
    "        rmse_lst.append(rmse)\n",
    "        norm_preds[idx] = y_pred\n",
    "    return rmse_lst, rf_lst, norm_preds\n",
    "\n",
    "def rfr(tpose_dt, y_dict):\n",
    "    train_rmse_lst = []\n",
    "    tst_rmse_lst = []\n",
    "    for idx in tpose_dt.keys():\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(tpose_dt[idx][0], y_dict[idx][0])\n",
    "        \n",
    "        train_pred = rf.predict(tpose_dt[idx][0])\n",
    "        train_rmse = root_mean_squared_error(y_dict[idx][0], train_pred)\n",
    "        train_rmse_lst.append(train_rmse)\n",
    "        \n",
    "        test_pred = rf.predict(tpose_dt[idx][1])\n",
    "        tst_rmse = root_mean_squared_error(y_dict[idx][1], test_pred)\n",
    "        tst_rmse_lst.append(tst_rmse)\n",
    "    return train_rmse_lst, tst_rmse_lst\n",
    "\n",
    "def rfr_cv(tpose_dt, y_dict):\n",
    "    train_rmse_lst = []\n",
    "    tst_rmse_lst = []\n",
    "    rf_lst = []\n",
    "    for idx in tpose_dt.keys():\n",
    "        rf = RandomForestRegressor()\n",
    "        rf_lst.append(rf)\n",
    "        rf.fit(tpose_dt[idx][0], y_dict[idx][0])\n",
    "        \n",
    "        train_pred = rf.predict(tpose_dt[idx][0])\n",
    "        train_rmse = root_mean_squared_error(y_dict[idx][0], train_pred)\n",
    "        train_rmse_lst.append(train_rmse)\n",
    "        \n",
    "        test_pred = rf.predict(tpose_dt[idx][1])\n",
    "        tst_rmse = root_mean_squared_error(y_dict[idx][1], test_pred)\n",
    "        tst_rmse_lst.append(tst_rmse)\n",
    "    return train_rmse_lst, tst_rmse_lst, rf_lst\n",
    "\n",
    "\n",
    "def rfr_params(tpose_dt, y_dict):\n",
    "    train_rmse_lst = []\n",
    "    tst_rmse_lst = []\n",
    "    rf_lst = []\n",
    "    for idx in tpose_dt.keys():\n",
    "        rf = RandomForestRegressor()\n",
    "        new = rf.fit(tpose_dt[idx][0], y_dict[idx][0])\n",
    "        rf_lst.append(new)\n",
    "        \n",
    "        train_pred = rf.predict(tpose_dt[idx][0])\n",
    "        train_rmse = root_mean_squared_error(y_dict[idx][0], train_pred)\n",
    "        train_rmse_lst.append(train_rmse)\n",
    "        \n",
    "        test_pred = rf.predict(tpose_dt[idx][1])\n",
    "        tst_rmse = root_mean_squared_error(y_dict[idx][1], test_pred)\n",
    "        tst_rmse_lst.append(tst_rmse)\n",
    "    return train_rmse_lst, tst_rmse_lst, rf_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be62ba-8fd7-4e01-bb17-36729320b9f9",
   "metadata": {},
   "source": [
    "#### Full Covariance for GMM used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ca25f-b8c9-42fd-b0e6-3f30d434e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = make_features(cluster_lst)\n",
    "c = split_data(b)\n",
    "d = rearrange(c,b)\n",
    "e = y_capture(c,b)\n",
    "f = make_clust_eq(d)\n",
    "full = rfr(f,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9bca2-9e92-4484-bc15-67f42bf75548",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = {\n",
    "    0: 'indigo',\n",
    "    1: 'red',\n",
    "    2: 'blue',\n",
    "    3: 'gold',\n",
    "    4: 'mediumorchid',\n",
    "    5: 'teal',\n",
    "    6: 'pink',\n",
    "    7: 'brown',\n",
    "}\n",
    "\n",
    "colors = ta_ed[\"Cluster\"].map(cluster_colors).tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "ax.coastlines(resolution='110m', color='black', linewidth=1)\n",
    "ax.add_feature(cfeature.LAND, facecolor = \"gainsboro\")\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.set_extent([120,-70,-60,60])\n",
    "ax.scatter(ta_ed[\"Longitude\"], ta_ed[\"Latitude\"], c=colors, s=5, transform=ccrs.PlateCarree())\n",
    "\n",
    "#ax.scatter(ta_ed[\"Longitude\"], ta_ed[\"Latitude\"],2, c = colors, transform=ccrs.PlateCarree())\n",
    "ax.set_title(\"Pacific Ocean Clusters\")\n",
    "\n",
    "handles = [plt.Line2D([0], [0], marker='o', color=color, markersize=5, label=f'Cluster {cluster}') for cluster, color in cluster_colors.items()]\n",
    "ax.legend(handles=handles, loc='upper right', title='Clusters', framealpha =1, fontsize='15', title_fontsize='15')\n",
    "#plt.show()\n",
    "plt.savefig(\"tst1.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e598f-97f3-4393-8e1a-109118d78d18",
   "metadata": {},
   "source": [
    "### Making overlapping clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce915a4f-08c5-4470-a4fc-68a5a3fd5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "join8=ta_ed.join(prob_df) #og df without any overlaps, size = 179894 rows\n",
    "##for loop to make the overlap\n",
    "new_rows = []\n",
    "for i in range(len(join8)): #go thru each row\n",
    "    cur_clust = join8[\"Cluster\"][i]\n",
    "    for j in range(8):\n",
    "        if j != cur_clust and prob_df.iloc[i,j] > .10:\n",
    "            row = join8.iloc[i].copy()\n",
    "            row[\"Cluster\"] = j\n",
    "            new_rows.append(row)\n",
    "join_new = join8._append(new_rows).reset_index(drop=True) #new df with overlaps (using the code above) and the size is 233435 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67df211-49d1-4f79-8aeb-4b46ba0b8c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ords_counts = join_new[\"order\"].value_counts()\n",
    "ords_cts = ords_counts.to_frame()\n",
    "ords_cts = ords_cts.reset_index()\n",
    "ords_cts = ords_cts.sort_values(by = \"order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8cba88-d3f6-436e-9ca3-4fddbdc3efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst2 = join_new.merge(ords_cts, on = \"order\")\n",
    "#len(tst1[tst1[\"count\"] == 2])+len(tst1[tst1[\"count\"] == 3])+ len(tst1[tst1[\"count\"] == 4])+ len(tst1[tst1[\"count\"] == 1])\n",
    "#tst2 = ords_cts[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb9222-55fd-4870-b3f8-d3b8083b123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##for loop to given the data points that are in several clusters a different color\n",
    "color_assign = []\n",
    "op = 8\n",
    "\n",
    "for i in range(len(tst2)):\n",
    "    ctr = tst2[\"count\"][i]\n",
    "    cur_col = join_new[\"Cluster\"][i]\n",
    "    if ctr == 1:\n",
    "        color_assign.append(cur_col)\n",
    "    else:\n",
    "        color_assign.append(op)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c9a0e-bc60-4c6f-84b8-426181387ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst2[\"overlap_cl\"] = color_assign\n",
    "tst2[\"overlap_cl\"] = tst2[\"overlap_cl\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a014088-1b5a-44cd-a778-856678894f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map to see the overlapping clusters\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "ax.coastlines()\n",
    "ax.set_extent([120,-70,-60,60])\n",
    "ax.scatter(tst1[\"Longitude\"], tst1[\"Latitude\"],.5, c = tst1[\"overlap_cl\"], transform=ccrs.PlateCarree())\n",
    "ax.set_title(\"Overlapping Clusters for 8 Clusters\")\n",
    "#plt.savefig(f'{jdx+1}Clusters.png')\n",
    "ax.set_label(\"Label via method\")\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "plt.savefig(\"full8cl.png\")\n",
    "\n",
    "#Larger map \n",
    "cluster_colors = {\n",
    "    0: 'indigo',\n",
    "    1: 'red',\n",
    "    2: 'blue',\n",
    "    3: 'gold',\n",
    "    4: 'mediumorchid',\n",
    "    5: 'teal',\n",
    "    6: 'pink',\n",
    "    7: 'brown',\n",
    "    8: 'papayawhip',\n",
    "}\n",
    "\n",
    "colors = tst2[\"overlap_cl\"].map(cluster_colors).tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "ax.coastlines(resolution='110m', color='black', linewidth=1)\n",
    "ax.add_feature(cfeature.LAND, facecolor = \"gainsboro\")\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.set_extent([120,-70,-60,60])\n",
    "ax.scatter(tst2[\"Longitude\"], tst2[\"Latitude\"], c=colors, s=5, transform=ccrs.PlateCarree())\n",
    "\n",
    "#ax.scatter(ta_ed[\"Longitude\"], ta_ed[\"Latitude\"],2, c = colors, transform=ccrs.PlateCarree())\n",
    "ax.set_title(\"Overlapping Pacific Ocean Clusters\")\n",
    "\n",
    "handles = [plt.Line2D([0], [0], marker='o', color=color, markersize=5, label=f'Cluster {cluster}') for cluster, color in cluster_colors.items()]\n",
    "ax.legend(handles=handles, loc='upper right', title='Clusters', framealpha =1, fontsize='15', title_fontsize='15')\n",
    "#plt.show()\n",
    "plt.savefig(\"overlap.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543734bf-e0d8-4472-9c70-15315cc30667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading a new csv with the updated cluster values\n",
    "tst2.to_csv(\"8clovlap2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d0399-1222-4b67-9529-e4ac06b558a2",
   "metadata": {},
   "source": [
    "### CV Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa622bdb-6997-419a-bd1e-64bb131bf74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the clusters out\n",
    "clust1a = tst2.loc[tst2[\"Cluster\"] ==0]\n",
    "clust2a = tst2.loc[tst2[\"Cluster\"] ==1]\n",
    "clust3a = tst2.loc[tst2[\"Cluster\"] ==2]\n",
    "clust4a = tst2.loc[tst2[\"Cluster\"] ==3]\n",
    "clust5a = tst2.loc[tst2[\"Cluster\"] ==4]\n",
    "clust6a = tst2.loc[tst2[\"Cluster\"] ==5]\n",
    "clust7a = tst2.loc[tst2[\"Cluster\"] ==6]\n",
    "clust8a = tst2.loc[tst2[\"Cluster\"] ==7]\n",
    "\n",
    "cluster_lsta = [clust1a, clust2a, clust3a, clust4a, clust5a, clust6a, clust7a, clust8a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d55f4-b1f1-4d89-8587-d83f90b40a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Map of Overlapping Clusters Separated Out\n",
    "# FULL COV \n",
    "for idx, data in enumerate(cluster_lsta):\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([120,-70,-60,60])\n",
    "    ax.scatter(data[\"Longitude\"], data[\"Latitude\"],.5, c = data[\"overlap_cl\"], transform=ccrs.PlateCarree())\n",
    "    ax.set_title(f'Overlapped Clustering for Cluster #{idx+1}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09975369-fa38-48c7-885d-3376194732b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = make_features(cluster_lsta)\n",
    "ca = split_data(ba)\n",
    "da = rearrange(ca,ba)\n",
    "ea = y_capture(ca,ba)\n",
    "orders = order_capture(ca,ba)\n",
    "fa = make_clust_eq(da)\n",
    "q = rfr_cv(fa,ea)\n",
    "\n",
    "par = rfr_params(fa,ea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89723bc6-d7f6-4722-9406-54a59d978d68",
   "metadata": {},
   "source": [
    "#### Cross Validation for Each Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb011927-5b8b-490e-9984-5fd0f6843fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for full covariance\n",
    "for i in range(len(q[2])):\n",
    "    kf = KFold(n_splits = 5)\n",
    "    X = fa[i][0]\n",
    "    y = ea[i][0]\n",
    "    scores = cross_val_score(q[2][i], X, y, cv=kf)\n",
    "    print(\"Cross Validation Scores: \", scores)\n",
    "    print(\"Average CV Score: \", scores.mean())\n",
    "    print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f17c29-a371-4e89-a735-64587445d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test set full covariance\n",
    "for i in range(len(q[2])):\n",
    "    print(q[2][i].score(fa[i][1], ea[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b011a83-276d-4635-a746-d48e6b6883ee",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57e59b8-11ec-448c-a1e0-0d6ff00f8272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyp_tr(tpose_dt, y_dict):\n",
    "    p_dist = {\"n_estimators\": range(50,500),\n",
    "          \"max_depth\": range(1,20),\n",
    "          \"max_features\": range(1,9)}\n",
    "    hyp_dict = {}\n",
    "    for idx in tpose_dt.keys(): \n",
    "        rf = RandomForestRegressor()\n",
    "        rs = HalvingGridSearchCV(rf, param_grid = p_dist, cv=5)\n",
    "        res = rs.fit(tpose_dt[idx][0], y_dict[idx][0])\n",
    "        hyp_dict[idx] = [list(res.best_params_.values())[0],list(res.best_params_.values())[1], list(res.best_params_.values())[2]]\n",
    "    return hyp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0cbe62-9665-4d9d-b1c2-b922fdeab773",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = make_features(cluster_lsta)\n",
    "c = split_data(b)\n",
    "d = rearrange(c,b)\n",
    "e = y_capture(c,b)\n",
    "f = make_clust_eq(d)\n",
    "g = rfr(f,e) #takes up a lot of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f962f-68a2-4591-9425-b863c6e7beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hyp_tr(f,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd36f6c-7ed2-4fef-870e-af1b52bbf9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(tpose_dt, y_dict, hyp_dict):\n",
    "    best_rmse = {}\n",
    "    best_dict = {}\n",
    "    for idx in tpose_dt.keys():\n",
    "        best_rf = RandomForestRegressor(max_depth=hyp_dict[idx][0], n_estimators=hyp_dict[idx][1], max_features = hyp_dict[idx][2])\n",
    "        best_rf.fit(tpose_dt[idx][0], y_dict[idx][0])\n",
    "        best_preds = best_rf.predict(tpose_dt[idx][1])\n",
    "        rmse = root_mean_squared_error(y_dict[idx][1], best_preds)\n",
    "        best_rmse[idx] = rmse\n",
    "        best_dict[idx] = best_preds\n",
    "    return best_rmse, best_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66798fe-f95e-4592-b03d-ab58be445e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = best_model(f,e,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf1dc2-f6a0-4973-9dfc-4401cc2b1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting TA Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459fd39-ea39-4624-9312-49052d62c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds(tpose_dt, y_dict):\n",
    "    train_preds = {}\n",
    "    test_preds = {}\n",
    "    for idx in tpose_dt.keys():\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(tpose_dt[idx][0], y_dict[idx][0])\n",
    "        train_pred = rf.predict(tpose_dt[idx][0])\n",
    "        train_preds[idx] = train_pred\n",
    "        test_pred = rf.predict(tpose_dt[idx][1])\n",
    "        test_preds[idx] = test_pred\n",
    "    return train_preds, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbddb5-cc2e-4370-87ba-65b9a503148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_ords_preds(test_preds, order_dict, y_dict):\n",
    "    clnum = []\n",
    "    ord_tst = []\n",
    "    pred_tst = []\n",
    "    actual_y = []\n",
    "    for idx in range(len(orders)):\n",
    "        cl_len = [idx]*len(orders[idx][1])\n",
    "        ord_tst.extend(orders[idx][1])\n",
    "        clnum.extend(cl_len)\n",
    "    for idx in range(len(y_dict)):\n",
    "        actual_y.extend(y_dict[idx][1])\n",
    "    for i in range(len(test_preds)):\n",
    "        pred_tst.extend(test_preds[i])\n",
    "    comb_df = pd.DataFrame( {\"Order_Num\": ord_tst,\n",
    "                             \"RFR1\": pred_tst,\n",
    "                             \"Y_test\": actual_y,\n",
    "                             \"Cluster\": clnum})\n",
    "    return comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09424363-2eb5-41e4-95de-f131c7ea6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the functions\n",
    "#first trying on overlapped 8cl, diag cov, no hypertuning\n",
    "trn, tsty = preds(fa,ea)\n",
    "\n",
    "#checking lengths to make sure there are no issues with test preds\n",
    "\n",
    "ordlen = []\n",
    "for i in range(len(orders)):\n",
    "    k=(len(orders[i][1]))\n",
    "    ordlen.append(k)\n",
    "sum(ordlen)\n",
    "\n",
    "#for i in range(len(samplepred1[1])):\n",
    "    #print(len(samplepred1[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ceb414-5191-42a5-851c-2638d2b2b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the predictions to a new csv (uncomment the next line to do so)\n",
    "#comb_ords_preds(tsty, orders, ea).to_csv(\"rfrpredsdiag.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
